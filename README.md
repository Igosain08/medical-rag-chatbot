# Medical RAG Chatbot

A Retrieval-Augmented Generation (RAG) chatbot for medical queries, built with Flask, LangChain, and HuggingFace models.

## ğŸ“‹ Project Overview

This project is a **Medical Question-Answering Chatbot** that uses:
- **Flask** for the web interface
- **LangChain** for RAG pipeline orchestration
- **HuggingFace Mistral-7B-Instruct** as the LLM
- **FAISS** for vector storage and similarity search
- **Sentence Transformers** for embeddings
- **PDF processing** to create a knowledge base from medical documents

### Architecture

```
User Query â†’ Flask App â†’ RetrievalQA Chain â†’ FAISS Vector Store â†’ LLM â†’ Response
```

1. **PDF Loader**: Loads medical PDFs from `data/` directory
2. **Text Chunking**: Splits documents into manageable chunks
3. **Embeddings**: Converts text chunks to vectors using HuggingFace embeddings
4. **Vector Store**: Stores embeddings in FAISS for fast similarity search
5. **Retriever**: Finds relevant context from vector store
6. **LLM**: Generates answers using Mistral-7B-Instruct model
7. **Web Interface**: Flask-based chat interface

## ğŸš€ Quick Start Guide

### Prerequisites

- **Python 3.10+** (Python 3.10 or higher)
- **HuggingFace Account** with API token
- **Git** (optional, for version control)

### Step 1: Navigate to Project Directory

```bash
cd CODE
```

### Step 2: Create Virtual Environment

**For macOS/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**For Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -e .
```

Or install directly from requirements.txt:
```bash
pip install -r requirements.txt
```

### Step 4: Set Up Environment Variables

1. Create a `.env` file in the `CODE` directory:
```bash
touch .env
```

2. Add your HuggingFace token:
```
HF_TOKEN=your_huggingface_token_here
```

**How to get HuggingFace Token:**
- Go to https://huggingface.co/settings/tokens
- Create a new token (read access is sufficient)
- Copy the token and paste it in `.env` file

### Step 5: Create Vector Store (IMPORTANT!)

Before running the app, you need to create the vector store from PDFs:

```bash
python -m app.components.data_loader
```

This will:
- Load PDFs from `data/` directory
- Split them into chunks
- Generate embeddings
- Save vector store to `vectorstore/db_faiss/`

**Note:** This step may take 10-30 minutes depending on PDF size and your internet connection (downloading embedding model).

### Step 6: Run the Application

```bash
python app/application.py
```

Or:
```bash
flask run
```

The app will be available at: **http://localhost:5000**

## ğŸ“ Project Structure

```
CODE/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ application.py          # Flask app entry point
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Main script to create vector store
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py       # PDF loading and chunking
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # HuggingFace embeddings
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # FAISS vector store operations
â”‚   â”‚   â”œâ”€â”€ retriever.py        # RAG chain creation
â”‚   â”‚   â””â”€â”€ llm.py              # LLM loading
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.py           # Configuration settings
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â”œâ”€â”€ logger.py           # Logging setup
â”‚   â”‚   â””â”€â”€ custom_exception.py # Custom exception handling
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html          # Chat interface
â”œâ”€â”€ data/
â”‚   â””â”€â”€ *.pdf                   # Medical PDF documents
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ db_faiss/               # Generated vector store (created after step 5)
â”œâ”€â”€ logs/                       # Application logs (auto-created)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ Dockerfile                  # Docker configuration
â””â”€â”€ .env                        # Environment variables (create this)
```

## âš™ï¸ Configuration

Edit `app/config/config.py` to customize:

- `HUGGINGFACE_REPO_ID`: LLM model (default: "mistralai/Mistral-7B-Instruct-v0.3")
- `DB_FAISS_PATH`: Vector store location (default: "vectorstore/db_faiss")
- `DATA_PATH`: PDF directory (default: "data/")
- `CHUNK_SIZE`: Text chunk size (default: 500)
- `CHUNK_OVERLAP`: Overlap between chunks (default: 50)

## ğŸ³ Docker Setup

### Build Docker Image

```bash
docker build -t medical-rag-chatbot .
```

### Run Docker Container

```bash
docker run -p 5000:5000 --env-file .env medical-rag-chatbot
```

**Note:** Make sure to create the vector store before building the Docker image, or mount the vectorstore directory.

## ğŸ”§ Troubleshooting

### Issue: "Vector store not present or empty"
**Solution:** Run `python -m app.components.data_loader` to create the vector store first.

### Issue: "HF_TOKEN not found"
**Solution:** Create `.env` file with `HF_TOKEN=your_token_here`

### Issue: "No pdfs were found"
**Solution:** Ensure PDF files are in the `data/` directory

### Issue: Slow first response
**Solution:** The embedding model downloads on first use. Subsequent runs will be faster.

### Issue: Import errors
**Solution:** Make sure virtual environment is activated and dependencies are installed: `pip install -e .`

## ğŸ“ Usage

1. Start the application
2. Open browser to http://localhost:5000
3. Type a medical question in the chat interface
4. The bot will retrieve relevant context from the medical encyclopedia and generate an answer
5. Click "Clear Chat" to start a new conversation

## ğŸ” Security Notes

- Never commit `.env` file to version control
- Keep your HuggingFace token secure
- The `.env` file is already in `.gitignore` (should be)

## ğŸ“š Dependencies

- `flask`: Web framework
- `langchain`: RAG pipeline
- `langchain_community`: Community integrations
- `langchain_huggingface`: HuggingFace integration
- `faiss-cpu`: Vector similarity search
- `pypdf`: PDF processing
- `huggingface_hub`: HuggingFace API
- `python-dotenv`: Environment variable management

## ğŸš€ CI/CD Pipeline

The project includes Jenkins CI/CD pipeline for:
- Automated testing
- Docker image building
- Security scanning with Trivy
- Deployment to AWS ECR
- Deployment to AWS App Runner

See `FULL_DOCUMENTATION.md` for detailed CI/CD setup instructions.

## ğŸ“„ License

This project is for educational/demonstration purposes.

## ğŸ¤ Contributing

Feel free to submit issues and enhancement requests!

